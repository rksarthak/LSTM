{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cbb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2d69e",
   "metadata": {},
   "source": [
    "## Data Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5293a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.729998</td>\n",
       "      <td>0.298912</td>\n",
       "      <td>0.741555</td>\n",
       "      <td>0.818164</td>\n",
       "      <td>0.580779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.184512</td>\n",
       "      <td>0.094818</td>\n",
       "      <td>0.881102</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.526972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>0.463180</td>\n",
       "      <td>0.946464</td>\n",
       "      <td>0.351037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.663281</td>\n",
       "      <td>0.180671</td>\n",
       "      <td>0.289179</td>\n",
       "      <td>0.843224</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.482089</td>\n",
       "      <td>0.203653</td>\n",
       "      <td>0.318847</td>\n",
       "      <td>0.918853</td>\n",
       "      <td>0.365097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  output\n",
       "0  0.374540  0.729998  0.298912  0.741555  0.818164  0.580779       1\n",
       "1  0.950714  0.184512  0.094818  0.881102  0.145270  0.526972       0\n",
       "2  0.731994  0.346640  0.126359  0.463180  0.946464  0.351037       1\n",
       "3  0.598658  0.663281  0.180671  0.289179  0.843224  0.493213       0\n",
       "4  0.156019  0.482089  0.203653  0.318847  0.918853  0.365097       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Number of samples\n",
    "num_samples = 20000\n",
    "# Create a DataFrame with 6 random features\n",
    "df = pd.DataFrame({\n",
    "    'feature1': np.random.rand(num_samples),\n",
    "    'feature2': np.random.rand(num_samples),\n",
    "    'feature3': np.random.rand(num_samples),\n",
    "    'feature4': np.random.rand(num_samples),\n",
    "    'feature5': np.random.rand(num_samples),\n",
    "    'feature6': np.random.rand(num_samples),\n",
    "    'output': np.random.choice([0, 1, 2], size=num_samples)  # Randomly assign one of three classes\n",
    "})\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1806a5",
   "metadata": {},
   "source": [
    "## Part-1 (LSTM model without return_sequences=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812ffea",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2633a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Step 1: Create Sequences and target \n",
    "sequence_length = 5 # time lags or time steps \n",
    "sequences = []\n",
    "targets= []\n",
    "for i in range(len(df) - sequence_length-1):\n",
    "    sequences.append(df.iloc[i:i+sequence_length].values)\n",
    "    targets.append(df.iloc[i+sequence_length+1].values[-1])\n",
    "#print(np.shape(sequences)) #(samples, time steps,features) here features consitute have features + output\n",
    "#print(np.shape(targets)) # (samples,)\n",
    "\n",
    "# Step-2 Splitting the data into test_train_validation set \n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, targets, test_size=0.2, random_state=42, stratify=targets)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "# Step 4: Reshape Data\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Reshape X_train, X_test,X_val to 3D arrays (samples, time steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], sequence_length, X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], sequence_length, X_test.shape[2])\n",
    "X_val = X_val.reshape(X_val.shape[0], sequence_length, X_val.shape[2])\n",
    "\n",
    "print(\"Shape of X_train data set\",X_train.shape) \n",
    "print(\"Shape of y_train data set\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc11cd",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a47aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=4,return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Compile the model with class weights\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44186fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min', \n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Define dynamic learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.1\n",
    "    if epoch > 50:\n",
    "        lr *= 0.5\n",
    "    elif epoch > 75:\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Compute class weights ( necessary if you have unbalanced datasets)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {class_index: weight for class_index, weight in enumerate(class_weights)}\n",
    "\n",
    "# Fit the model \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=256, validation_data=(X_test, y_test), \n",
    "                    callbacks=[early_stopping, lr_scheduler],class_weight=class_weights_dict,verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166b89",
   "metadata": {},
   "source": [
    "### Visualization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d508a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Extract loss history and learning rates\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "learning_rates = [lr_schedule(epoch) for epoch in range(1, len(train_loss) + 1)]\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot loss with respect to epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot learning rate with respect to epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, learning_rates, 'g', label='Learning Rate')\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cbfe5",
   "metadata": {},
   "source": [
    "### Prediction on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a848d65",
   "metadata": {},
   "source": [
    "## Part-2 (LSTM model without return_sequences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621717b9",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Step 1: Create Sequences and target \n",
    "sequence_length = 5 # time lags or time steps \n",
    "sequences = []\n",
    "targets= []\n",
    "for i in range(len(df) - sequence_length-1):\n",
    "    sequences.append(df.iloc[i:i+sequence_length].values)\n",
    "    targets.append(df.iloc[i+1:i+1+sequence_length,-1]) # only change happened here \n",
    "#print(np.shape(sequences)) #(samples, time steps,features) here features consitute have features + output\n",
    "#print(np.shape(targets)) # (samples,)\n",
    "\n",
    "# Step-2 Splitting the data into test_train_validation set \n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, targets, test_size=0.2, random_state=42, stratify=targets)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "# Step 4: Reshape Data\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Reshape X_train, X_test,X_val to 3D arrays (samples, time steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], sequence_length, X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], sequence_length, X_test.shape[2])\n",
    "X_val = X_val.reshape(X_val.shape[0], sequence_length, X_val.shape[2])\n",
    "\n",
    "print(\"Shape of X_train data set\",X_train.shape) \n",
    "print(\"Shape of y_train data set\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0008d",
   "metadata": {},
   "source": [
    "### modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a348e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=4,return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9e3e3",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min', \n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Define dynamic learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.1\n",
    "    if epoch > 50:\n",
    "        lr *= 0.5\n",
    "    elif epoch > 75:\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# Fit the model \n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test), \n",
    "                    callbacks=[early_stopping, lr_scheduler])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f00c9",
   "metadata": {},
   "source": [
    "### Visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss history and learning rates\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "learning_rates = [lr_schedule(epoch) for epoch in range(1, len(train_loss) + 1)]\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot loss with respect to epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot learning rate with respect to epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, learning_rates, 'g', label='Learning Rate')\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2968c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
